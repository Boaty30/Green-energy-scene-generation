{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(os.getcwd())\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:33.795574Z",
     "iopub.execute_input": "2023-04-02T07:28:33.795880Z",
     "iopub.status.idle": "2023-04-02T07:28:33.875221Z",
     "shell.execute_reply.started": "2023-04-02T07:28:33.795851Z",
     "shell.execute_reply": "2023-04-02T07:28:33.873998Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install einops ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:33.877588Z",
     "iopub.execute_input": "2023-04-02T07:28:33.877963Z",
     "iopub.status.idle": "2023-04-02T07:28:48.566414Z",
     "shell.execute_reply.started": "2023-04-02T07:28:33.877926Z",
     "shell.execute_reply": "2023-04-02T07:28:48.564487Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\nimport math\nfrom inspect import isfunction\nfrom functools import partial\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom einops import rearrange\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:48.570087Z",
     "iopub.execute_input": "2023-04-02T07:28:48.570855Z",
     "iopub.status.idle": "2023-04-02T07:28:52.637441Z",
     "shell.execute_reply.started": "2023-04-02T07:28:48.570756Z",
     "shell.execute_reply": "2023-04-02T07:28:52.636407Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(torch.cuda.is_available)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.640449Z",
     "iopub.execute_input": "2023-04-02T07:28:52.641092Z",
     "iopub.status.idle": "2023-04-02T07:28:52.647582Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.641046Z",
     "shell.execute_reply": "2023-04-02T07:28:52.646491Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 判断变量是否为None\ndef exists(x):\n    return x is not None\n\n# 实现一个三元判断，传入val和default，如果val纯在，直接返回val，否则返回d\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d\n\n# 声明了一个残差网络\nclass Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n\n    def forward(self, x, *args, **kwargs):\n        return self.fn(x, *args, **kwargs) + x\n\n# 上采样\ndef Upsample(dim):\n    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n\n# 下采样\ndef Downsample(dim):\n    return nn.Conv2d(dim, dim, 4, 2, 1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.648898Z",
     "iopub.execute_input": "2023-04-02T07:28:52.649822Z",
     "iopub.status.idle": "2023-04-02T07:28:52.660533Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.649767Z",
     "shell.execute_reply": "2023-04-02T07:28:52.659525Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class SinusoidalPositionEmbeddings(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, time):\n        device = time.device\n        half_dim = self.dim // 2\n        embeddings = math.log(10000) / (half_dim - 1)\n        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n        embeddings = time[:, None] * embeddings[None, :]\n        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n        return embeddings",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.663503Z",
     "iopub.execute_input": "2023-04-02T07:28:52.665353Z",
     "iopub.status.idle": "2023-04-02T07:28:52.672825Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.665308Z",
     "shell.execute_reply": "2023-04-02T07:28:52.671718Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 基础的神经网络会用到的层，定义了层里面的两个基本操作，卷积和归一化以及激活函数\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, groups = 8):\n        super().__init__()\n        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n        self.norm = nn.GroupNorm(groups, dim_out)\n        self.act = nn.SiLU()\n\n    def forward(self, x, scale_shift = None):\n        x = self.proj(x)\n        x = self.norm(x)\n\n        if exists(scale_shift):\n            scale, shift = scale_shift\n            x = x * (scale + 1) + shift\n\n        x = self.act(x)\n        return x\n\n# 残差网络的构建\nclass ResnetBlock(nn.Module):\n    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n    \n    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n        super().__init__()\n        self.mlp = (\n            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n            if exists(time_emb_dim)\n            else None\n        )\n\n        self.block1 = Block(dim, dim_out, groups=groups)\n        self.block2 = Block(dim_out, dim_out, groups=groups)\n        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb=None):\n        h = self.block1(x)\n\n        if exists(self.mlp) and exists(time_emb):\n            time_emb = self.mlp(time_emb)\n            h = rearrange(time_emb, \"b c -> b c 1 1\") + h\n\n        h = self.block2(h)\n        return h + self.res_conv(x)\n\n# 定义之前提到的ConvNeXt网络\nclass ConvNextBlock(nn.Module):\n    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n\n    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n        super().__init__()\n        self.mlp = (\n            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n            if exists(time_emb_dim)\n            else None\n        )\n\n        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n\n        self.net = nn.Sequential(\n            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n            nn.GELU(),\n            nn.GroupNorm(1, dim_out * mult),\n            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n        )\n\n        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb=None):\n        h = self.ds_conv(x)\n\n        if exists(self.mlp) and exists(time_emb):\n            condition = self.mlp(time_emb)\n            h = h + rearrange(condition, \"b c -> b c 1 1\")\n\n        h = self.net(h)\n        return h + self.res_conv(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.674639Z",
     "iopub.execute_input": "2023-04-02T07:28:52.675108Z",
     "iopub.status.idle": "2023-04-02T07:28:52.693866Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.675071Z",
     "shell.execute_reply": "2023-04-02T07:28:52.692819Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Attention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n        )\n        q = q * self.scale\n\n        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n        attn = sim.softmax(dim=-1)\n\n        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n        return self.to_out(out)\n\nclass LinearAttention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n\n        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1), \n                                    nn.GroupNorm(1, dim))\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n        )\n\n        q = q.softmax(dim=-2)\n        k = k.softmax(dim=-1)\n\n        q = q * self.scale\n        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n\n        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n        return self.to_out(out)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.697278Z",
     "iopub.execute_input": "2023-04-02T07:28:52.697772Z",
     "iopub.status.idle": "2023-04-02T07:28:52.713547Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.697745Z",
     "shell.execute_reply": "2023-04-02T07:28:52.712559Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.fn = fn\n        self.norm = nn.GroupNorm(1, dim)\n\n    def forward(self, x):\n        x = self.norm(x)\n        return self.fn(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.717179Z",
     "iopub.execute_input": "2023-04-02T07:28:52.717429Z",
     "iopub.status.idle": "2023-04-02T07:28:52.727482Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.717405Z",
     "shell.execute_reply": "2023-04-02T07:28:52.726467Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Unet(nn.Module):\n    def __init__(\n        self,\n        dim,\n        init_dim=None,\n        out_dim=None,\n        dim_mults=(1, 2, 4, 8),\n        channels=3,\n        with_time_emb=True,\n        resnet_block_groups=8,\n        use_convnext=True,\n        convnext_mult=2,\n    ):\n        super().__init__()\n\n        # determine dimensions\n        self.channels = channels\n\n        init_dim = default(init_dim, dim // 3 * 2)\n        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n        \n        if use_convnext:\n            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n        else:\n            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n\n        # time embeddings\n        if with_time_emb:\n            time_dim = dim * 4\n            self.time_mlp = nn.Sequential(\n                SinusoidalPositionEmbeddings(dim),\n                nn.Linear(dim, time_dim),\n                nn.GELU(),\n                nn.Linear(time_dim, time_dim),\n            )\n        else:\n            time_dim = None\n            self.time_mlp = None\n\n        # layers\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(\n                nn.ModuleList(\n                    [\n                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n                        Downsample(dim_out) if not is_last else nn.Identity(),\n                    ]\n                )\n            )\n\n        mid_dim = dims[-1]\n        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.ups.append(\n                nn.ModuleList(\n                    [\n                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n                        Upsample(dim_in) if not is_last else nn.Identity(),\n                    ]\n                )\n            )\n\n        out_dim = default(out_dim, channels)\n        self.final_conv = nn.Sequential(\n            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n        )\n\n    def forward(self, x, time):\n        x = self.init_conv(x)\n\n        t = self.time_mlp(time) if exists(self.time_mlp) else None\n\n        h = []\n\n        # downsample\n        for block1, block2, attn, downsample in self.downs:\n            x = block1(x, t)\n            x = block2(x, t)\n            x = attn(x)\n            h.append(x)\n            x = downsample(x)\n\n        # bottleneck\n        x = self.mid_block1(x, t)\n        x = self.mid_attn(x)\n        x = self.mid_block2(x, t)\n\n        # upsample\n        for block1, block2, attn, upsample in self.ups:\n            x = torch.cat((x, h.pop()), dim=1)\n            x = block1(x, t)\n            x = block2(x, t)\n            x = attn(x)\n            x = upsample(x)\n\n        return self.final_conv(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.732566Z",
     "iopub.execute_input": "2023-04-02T07:28:52.732974Z",
     "iopub.status.idle": "2023-04-02T07:28:52.753382Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.732948Z",
     "shell.execute_reply": "2023-04-02T07:28:52.752300Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def cosine_beta_schedule(timesteps, s=0.008):\n    \"\"\"\n    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n    \"\"\"\n    steps = timesteps + 1\n    x = torch.linspace(0, timesteps, steps)\n    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    return torch.clip(betas, 0.0001, 0.9999)\n\ndef linear_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    return torch.linspace(beta_start, beta_end, timesteps)\n\ndef quadratic_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n\ndef sigmoid_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    betas = torch.linspace(-6, 6, timesteps)\n    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.755067Z",
     "iopub.execute_input": "2023-04-02T07:28:52.756200Z",
     "iopub.status.idle": "2023-04-02T07:28:52.767923Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.756165Z",
     "shell.execute_reply": "2023-04-02T07:28:52.767034Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "timesteps = 200\n\n# define beta schedule\nbetas = linear_beta_schedule(timesteps=timesteps)\n\n# define alphas \nalphas = 1. - betas\nalphas_cumprod = torch.cumprod(alphas, axis=0)\nalphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\nsqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n\n# calculations for diffusion q(x_t | x_{t-1}) and others\nsqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\nsqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n\n# calculations for posterior q(x_{t-1} | x_t, x_0)\nposterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n\ndef extract(a, t, x_shape):\n    batch_size = t.shape[0]\n    out = a.gather(-1, t.cpu())\n    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.769176Z",
     "iopub.execute_input": "2023-04-02T07:28:52.769867Z",
     "iopub.status.idle": "2023-04-02T07:28:52.995491Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.769831Z",
     "shell.execute_reply": "2023-04-02T07:28:52.994169Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# forward diffusion (using the nice property)\ndef q_sample(x_start, t, noise=None):\n    if noise is None:\n        noise = torch.randn_like(x_start)\n\n    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n    sqrt_one_minus_alphas_cumprod_t = extract(\n        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n    )\n\n    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:52.996937Z",
     "iopub.execute_input": "2023-04-02T07:28:52.998068Z",
     "iopub.status.idle": "2023-04-02T07:28:53.004748Z",
     "shell.execute_reply.started": "2023-04-02T07:28:52.998024Z",
     "shell.execute_reply": "2023-04-02T07:28:53.003508Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\n# use seed for reproducability\ntorch.manual_seed(0)\n\n# source: https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\ndef plot(imgs, with_orig=False, row_title=None, **imshow_kwargs):\n    if not isinstance(imgs[0], list):\n        # Make a 2d grid even if there's just 1 row\n        imgs = [imgs]\n\n    num_rows = len(imgs)\n    num_cols = len(imgs[0]) + with_orig\n    fig, axs = plt.subplots(figsize=(200,200), nrows=num_rows, ncols=num_cols, squeeze=False)\n    for row_idx, row in enumerate(imgs):\n        row = [image] + row if with_orig else row\n        for col_idx, img in enumerate(row):\n            ax = axs[row_idx, col_idx]\n            ax.imshow(np.asarray(img), **imshow_kwargs)\n            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n\n    if with_orig:\n        axs[0, 0].set(title='Original image')\n        axs[0, 0].title.set_size(8)\n    if row_title is not None:\n        for row_idx in range(num_rows):\n            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n\n    plt.tight_layout()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.006659Z",
     "iopub.execute_input": "2023-04-02T07:28:53.007113Z",
     "iopub.status.idle": "2023-04-02T07:28:53.024495Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.007074Z",
     "shell.execute_reply": "2023-04-02T07:28:53.023364Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def p_losses(denoise_model, x_start, t, noise=None, loss_type=\"l1\"):\n    if noise is None:\n        noise = torch.randn_like(x_start)\n\n    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)\n    predicted_noise = denoise_model(x_noisy, t)\n\n    if loss_type == 'l1':\n        loss = F.l1_loss(noise, predicted_noise)\n    elif loss_type == 'l2':\n        loss = F.mse_loss(noise, predicted_noise)\n    elif loss_type == \"huber\":\n        loss = F.smooth_l1_loss(noise, predicted_noise)\n    else:\n        raise NotImplementedError()\n\n    return loss",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.026516Z",
     "iopub.execute_input": "2023-04-02T07:28:53.027061Z",
     "iopub.status.idle": "2023-04-02T07:28:53.037092Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.027022Z",
     "shell.execute_reply": "2023-04-02T07:28:53.036163Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "image_size = 24\nchannels = 1\nbatch_size = 128",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.039632Z",
     "iopub.execute_input": "2023-04-02T07:28:53.039950Z",
     "iopub.status.idle": "2023-04-02T07:28:53.051860Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.039922Z",
     "shell.execute_reply": "2023-04-02T07:28:53.050824Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 这个函数完整的实现了采样所用到的公式，实现了采样过程算法，一个子过程\n@torch.no_grad()\ndef p_sample(model, x, t, t_index):\n    betas_t = extract(betas, t, x.shape)\n    sqrt_one_minus_alphas_cumprod_t = extract(\n        sqrt_one_minus_alphas_cumprod, t, x.shape\n    )\n    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n    \n    # Equation 11 in the paper\n    # Use our model (noise predictor) to predict the mean\n    model_mean = sqrt_recip_alphas_t * (\n        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n    )\n\n    if t_index == 0:\n        return model_mean\n    else:\n        posterior_variance_t = extract(posterior_variance, t, x.shape)\n        noise = torch.randn_like(x)\n        # Algorithm 2 line 4:\n        return model_mean + torch.sqrt(posterior_variance_t) * noise \n\n# 这个函数就是使用模型，带入图片，不断去做采样\n# Algorithm 2 (including returning all images)\n@torch.no_grad()\ndef p_sample_loop(model, shape):\n    device = next(model.parameters()).device\n\n    b = shape[0]\n    # start from pure noise (for each example in the batch)\n    img = torch.randn(shape, device=device)\n    imgs = []\n\n    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n        imgs.append(img.cpu().numpy())\n    return imgs\n\n# 函数入口\n@torch.no_grad()\ndef sample(model, image_size, batch_size=16, channels=3):\n    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.053243Z",
     "iopub.execute_input": "2023-04-02T07:28:53.053667Z",
     "iopub.status.idle": "2023-04-02T07:28:53.067947Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.053640Z",
     "shell.execute_reply": "2023-04-02T07:28:53.066908Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from pathlib import Path\n\ndef num_to_groups(num, divisor):\n    groups = num // divisor\n    remainder = num % divisor\n    arr = [divisor] * groups\n    if remainder > 0:\n        arr.append(remainder)\n    return arr\n\nresults_folder = Path(\"./kaggle/temp\")\n# results_folder.mkdir(exist_ok = True)\nsave_and_sample_every = 1000",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.069732Z",
     "iopub.execute_input": "2023-04-02T07:28:53.070237Z",
     "iopub.status.idle": "2023-04-02T07:28:53.095029Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.070198Z",
     "shell.execute_reply": "2023-04-02T07:28:53.093818Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from torch.optim import Adam\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = Unet(\n    dim=image_size,\n    channels=channels,\n    dim_mults=(1, 2, 4,)\n)\nmodel.to(device)\n\noptimizer = Adam(model.parameters(), lr=1e-3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:53.096683Z",
     "iopub.execute_input": "2023-04-02T07:28:53.097503Z",
     "iopub.status.idle": "2023-04-02T07:28:57.242113Z",
     "shell.execute_reply.started": "2023-04-02T07:28:53.097468Z",
     "shell.execute_reply": "2023-04-02T07:28:57.241035Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\nimport sys\nfrom numpy import shape\nsys.path.append('..')\nimport numpy as np\nimport csv\ndef load_wind():\n    #Example dataset created for evnet_based GANs wind scenarios generation\n    # Data from NREL wind integrated datasets\n    with open('../input/aigcdatasets/wind.csv', 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        rows = [row for row in reader]\n    rows = np.array(rows, dtype=float)\n    trX = []\n    print(shape(rows))\n    m = np.ndarray.max(rows)\n    print(\"Maximum value of wind\", m)\n    print(shape(rows))\n    for x in range(rows.shape[1]):\n        train = rows[:-288, x].reshape(-1, 576)\n        train = train / 16\n\n        # print(shape(train))\n        if trX == []:\n            trX = train\n        else:\n            trX = np.concatenate((trX, train), axis=0)\n    print(\"Shape TrX\", shape(trX))\n\n    with open('../input/aigcdatasets/wind label.csv', 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        rows = [row for row in reader]\n    label = np.array(rows, dtype=int)\n    index = np.arange(len(trX))\n    np.random.shuffle(index)\n    trX = trX[index]\n    label = label[index]\n    print(\"Label shape\", shape(label))\n    return trX[:7098], label, trX[7098:]\n\ntrX, trY,trX_train=load_wind()\nprint('shape of trX,trXtrain',trX.shape,trX_train.shape)\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:34:00.855693Z",
     "iopub.execute_input": "2023-04-02T07:34:00.856494Z",
     "iopub.status.idle": "2023-04-02T07:34:02.636754Z",
     "shell.execute_reply.started": "2023-04-02T07:34:00.856455Z",
     "shell.execute_reply": "2023-04-02T07:34:02.635473Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# print(trX.shape)\n# trX.to(device)\n# trY = torch.from_numpy(trY).to(device)\n# ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.631594Z",
     "iopub.status.idle": "2023-04-02T07:28:59.632474Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.632181Z",
     "shell.execute_reply": "2023-04-02T07:28:59.632207Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(device)\n# 这边没有to(device)\ntrX = torch.tensor(trX, dtype=torch.float32)\nprint(trX.dtype)\nprint(len(trX))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:34:19.671107Z",
     "iopub.execute_input": "2023-04-02T07:34:19.672096Z",
     "iopub.status.idle": "2023-04-02T07:34:19.695805Z",
     "shell.execute_reply.started": "2023-04-02T07:34:19.672046Z",
     "shell.execute_reply": "2023-04-02T07:34:19.694587Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from torchvision.utils import save_image\n\nepochs = 20\nbatch_size = 32\nfor epoch in range(epochs):\n    step = 0\n#     for step, batch in enumerate(dataloader):\n    for start, end in zip(\n        range(0, len(trX), batch_size),\n        range(batch_size, len(trX), batch_size)\n        ):\n      step = step+1\n      optimizer.zero_grad()\n      batch = trX[start:end].reshape([-1, 1, 24,24]).to(device)\n#       batch_size = batch[\"pixel_values\"].shape[0]\n#       batch = batch[\"pixel_values\"].to(device)\n      \n      # 国内版启用这段，注释上面两行\n      # batch_size = batch[0].shape[0]\n      # batch = batch[0].to(device)\n\n      # Algorithm 1 line 3: sample t uniformally for every example in the batch\n      t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n      \n      loss = p_losses(model, batch, t, loss_type=\"huber\")\n\n      if step % 10 == 0:  # 本来是100\n        print(\"Loss:\", loss.item())\n\n      loss.backward()\n      optimizer.step()\n\n      # save generated images 下面先注释掉了\n#       if step != 0 and step % save_and_sample_every == 0:\n#         milestone = step // save_and_sample_every\n#         batches = num_to_groups(4, batch_size)\n#         all_images_list = list(map(lambda n: sample(model, batch_size=n, channels=channels), batches))\n#         all_images = torch.cat(all_images_list, dim=0)\n#         all_images = (all_images + 1) * 0.5\n#         save_image(all_images, str(results_folder / f'sample-{milestone}.png'), nrow = 6)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:34:23.274156Z",
     "iopub.execute_input": "2023-04-02T07:34:23.275311Z",
     "iopub.status.idle": "2023-04-02T07:34:48.022616Z",
     "shell.execute_reply.started": "2023-04-02T07:34:23.275271Z",
     "shell.execute_reply": "2023-04-02T07:34:48.020359Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "samples = sample(model, image_size=image_size, batch_size=64, channels=channels)\n\n# show a random one\nrandom_index = 5\n#plt.imshow(samples[-1][random_index].reshape(image_size, image_size, channels), cmap=\"gray\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.639085Z",
     "iopub.status.idle": "2023-04-02T07:28:59.639917Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.639628Z",
     "shell.execute_reply": "2023-04-02T07:28:59.639654Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "random_index = 10\nprint(samples[-1][random_index].shape)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.641415Z",
     "iopub.status.idle": "2023-04-02T07:28:59.642247Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.641994Z",
     "shell.execute_reply": "2023-04-02T07:28:59.642020Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "np.save('gen_sce.npy',samples[-1])\nnp.save('trX_t.npy',trX)\nnp.save('trX_test.npy',trX_train)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.643672Z",
     "iopub.status.idle": "2023-04-02T07:28:59.644569Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.644243Z",
     "shell.execute_reply": "2023-04-02T07:28:59.644276Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "a = np.load('gen_sce.npy')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.646240Z",
     "iopub.status.idle": "2023-04-02T07:28:59.647206Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.646920Z",
     "shell.execute_reply": "2023-04-02T07:28:59.646948Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(a.shape)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.648710Z",
     "iopub.status.idle": "2023-04-02T07:28:59.649608Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.649308Z",
     "shell.execute_reply": "2023-04-02T07:28:59.649334Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "aa = samples[-1][random_index].reshape(image_size, image_size, channels)\nprint(aa.shape)\nbb = aa.reshape(1,576)\nplt.plot(list(range(288)),bb[0][:288])\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.651200Z",
     "iopub.status.idle": "2023-04-02T07:28:59.652130Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.651833Z",
     "shell.execute_reply": "2023-04-02T07:28:59.651861Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# import matplotlib.animation as animation\n\n# random_index = 53\n\n# fig = plt.figure()\n# ims = []\n# for i in range(timesteps):\n#     im = plt.imshow(samples[i][random_index].reshape(image_size, image_size, channels), cmap=\"gray\", animated=True)\n#     ims.append([im])\n\n# animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n# animate.save('diffusion.gif')\n# plt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T07:28:59.653694Z",
     "iopub.status.idle": "2023-04-02T07:28:59.654618Z",
     "shell.execute_reply.started": "2023-04-02T07:28:59.654311Z",
     "shell.execute_reply": "2023-04-02T07:28:59.654357Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
