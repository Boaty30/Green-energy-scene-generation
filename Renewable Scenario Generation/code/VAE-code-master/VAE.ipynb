{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建VAE网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1, 24, 24)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 1, 24, 24)     5           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 64, 12, 12)    320         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 64, 12, 12)    36928       conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 64, 12, 12)    36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 9216)          0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           1179776     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 2)             0           dense_2[0][0]                    \n",
      "                                                                   dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 128)           384         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 9216)          1188864     dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 64, 12, 12)    0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 64, 12, 12)    36928       reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 64, 12, 12)    36928       conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 64, 25, 25)    36928       conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 1, 24, 24)     257         conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_1 (Cust [(None, 1, 24, 24), ( 0           input_1[0][0]                    \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2,554,762\n",
      "Trainable params: 2,554,762\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenh\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:129: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "gen_rows, gen_cols, gen_chns = 24, 24, 1\n",
    "# number of convolutional filters to use\n",
    "filters = 64\n",
    "# convolution kernel size\n",
    "num_conv = 3\n",
    "\n",
    "batch_size = 100\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_gen_size = (gen_chns, gen_rows, gen_cols)\n",
    "else:\n",
    "    original_gen_size = (gen_rows, gen_cols, gen_chns)\n",
    "latent_dim = 5\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0\n",
    "epochs = 5\n",
    "\n",
    "x = Input(shape=original_gen_size)\n",
    "conv_1 = Conv2D(gen_chns,\n",
    "                kernel_size=(2, 2),\n",
    "                padding='same', activation='relu')(x)\n",
    "conv_2 = Conv2D(filters,\n",
    "                kernel_size=(2, 2),\n",
    "                padding='same', activation='relu',\n",
    "                strides=(2, 2))(conv_1)\n",
    "conv_3 = Conv2D(filters,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same', activation='relu',\n",
    "                strides=1)(conv_2)\n",
    "conv_4 = Conv2D(filters,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same', activation='relu',\n",
    "                strides=1)(conv_3)\n",
    "flat = Flatten()(conv_4)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(filters * 12 * 12, activation='relu')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    output_shape = (batch_size, filters, 12, 12)\n",
    "else:\n",
    "    output_shape = (batch_size, 12, 12, filters)\n",
    "\n",
    "decoder_reshape = Reshape(output_shape[1:])\n",
    "decoder_deconv_1 = Conv2DTranspose(filters,\n",
    "                                   kernel_size=num_conv,\n",
    "                                   padding='same',\n",
    "                                   strides=1,\n",
    "                                   activation='relu')\n",
    "decoder_deconv_2 = Conv2DTranspose(filters,\n",
    "                                   kernel_size=num_conv,\n",
    "                                   padding='same',\n",
    "                                   strides=1,\n",
    "                                   activation='relu')\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    output_shape = (batch_size, filters, 25, 25)\n",
    "else:\n",
    "    output_shape = (batch_size, 25, 25, filters)\n",
    "decoder_deconv_3_upsamp = Conv2DTranspose(filters,\n",
    "                                          kernel_size=(3, 3),\n",
    "                                          strides=(2, 2),\n",
    "                                          padding='valid',\n",
    "                                          activation='relu')\n",
    "decoder_mean_squash = Conv2D(gen_chns,\n",
    "                             kernel_size=2,\n",
    "                             padding='valid',\n",
    "                             activation='sigmoid')\n",
    "\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded = decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "\n",
    "\n",
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean_squash):\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean_squash = K.flatten(x_decoded_mean_squash)\n",
    "        xent_loss = gen_rows * gen_cols * metrics.binary_crossentropy(x, x_decoded_mean_squash)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean_squash = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean_squash)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We don't use this output.\n",
    "        return x\n",
    "\n",
    "\n",
    "y = CustomVariationalLayer()([x, x_decoded_mean_squash])\n",
    "vae = Model(x, y)\n",
    "vae.compile(optimizer='adam', loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=200,\n",
    "        batch_size=128,\n",
    "        validation_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取解码器部分作为生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_hid_decoded = decoder_hid(decoder_input)\n",
    "_up_decoded = decoder_upsample(_hid_decoded)\n",
    "_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n",
    "_deconv_2_decoded = decoder_deconv_2(_deconv_1_decoded)\n",
    "_x_decoded_relu = decoder_deconv_3_upsamp(_deconv_2_decoded)\n",
    "_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n",
    "generator = Model(decoder_input, _x_decoded_mean_squash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result = generator.predict(np.random.normal(size=(200000,5)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
